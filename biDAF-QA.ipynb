{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-directional Attention Flow\n",
    "\n",
    "This notebook shows how to use [BiDAF](arxiv.org/abs/1611.01603) for Question Answering, exatracting information from a context paragaph.\n",
    "We will be using the [AllenNLP](https://github.com/allenai/allennlp) library built on top of [PyTorch](https://pytorch.org/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp import predictors\n",
    "from allennlp.predictors import Predictor\n",
    "from allennlp.models.archival import load_archive\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class PretrainedModel:\n",
    "    \"\"\"\n",
    "    A pretrained model is determined by both an archive file\n",
    "    (representing the trained model)\n",
    "    and a choice of predictor.\n",
    "    \"\"\"\n",
    "    def __init__(self, archive_file: str, predictor_name: str) -> None:\n",
    "        self.archive_file = archive_file\n",
    "        self.predictor_name = predictor_name\n",
    "\n",
    "    def predictor(self) -> Predictor:\n",
    "        archive = load_archive(self.archive_file)\n",
    "        return Predictor.from_archive(archive, self.predictor_name)\n",
    "\n",
    "def bidirectional_attention_flow_seo_2017() -> predictors.BidafPredictor:\n",
    "    model = PretrainedModel(\n",
    "        'https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz',\n",
    "        'machine-comprehension'\n",
    "    )\n",
    "    return model.predictor() # type: ignore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some helper function to handle the output and take a sneak peak into the model attention mechanism:\n",
    "\n",
    "def build_answer(ans):\n",
    "    return ans['best_span_str']\n",
    "#     return \" \".join(ans['passage_tokens'][start:end])\n",
    "\n",
    "def get_span_probs(ans):\n",
    "    start, end = ans['best_span'][0], ans['best_span'][1]\n",
    "    return ans['span_start_probs'][start], ans['span_end_probs'][end]\n",
    "\n",
    "def plot_attention(ans):\n",
    "    # Retrieve answer relevant information\n",
    "    energies = np.array(ans['passage_question_attention'], dtype=np.float32)\n",
    "    question_tokens = ans['question_tokens']\n",
    "    passage_tokens = ans['passage_tokens']\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 100))\n",
    "    m = ax.imshow(energies, plt.get_cmap(\"Blues\"))\n",
    "    \n",
    "    # Use each token...\n",
    "    ax.set_xticks(np.arange(len(question_tokens)))\n",
    "    ax.set_yticks(np.arange(len(passage_tokens)))\n",
    "    \n",
    "    # ... to label the axis\n",
    "    ax.xaxis.set_tick_params(labeltop=True)\n",
    "    ax.set_xticklabels(question_tokens, rotation=75)\n",
    "    ax.set_yticklabels(passage_tokens)\n",
    "    \n",
    "    # Create a colorbar\n",
    "    cbar = plt.colorbar(m)\n",
    "    cbar.ax.set_ylabel(\"attention weight\", rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a passage from where to extract information:\n",
    "# An example passage could be the following:\n",
    "\"\"\"\n",
    "The history of the penny of Great Britain and the United Kingdom from 1714 to 1901, \n",
    "the period in which the House of Hanover reigned, saw its transformation from a small \n",
    "silver coin to a larger bronze piece. All bear the portrait of the monarch on the obverse; \n",
    "copper and bronze pennies have a depiction of Britannia on the reverse. During most of the 18th century, \n",
    "the penny was a small silver coin rarely seen in circulation. Beginning in 1787, \n",
    "the chronic shortage of good money resulted in the wide circulation of private tokens, \n",
    "including ones valued at one penny. In 1797 Matthew Boulton gained a government contract \n",
    "and struck millions of pennies. The copper penny continued to be issued until 1860, \n",
    "when they were replaced by lighter bronze coins; the \"Bun penny\", \n",
    "named for the hairstyle of Queen Victoria on it, was issued from then until 1894. \n",
    "The final years of her reign saw the \"Old head\" pennies, coined from 1895 until her death in 1901\n",
    "\"\"\"\n",
    "passage = input(\"Input a text passage you would like to ask questions about\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# here we define the question and make a prediction.\n",
    "# Some questions examples:\n",
    "#    When was the 'Old Head' penny coined?\n",
    "#    How was the penny called due to Queen Victoria hairstyle?\n",
    "#    When did Matthew boulton gain the government contract?\n",
    "#    What is depicted in the reverse of the penny?\n",
    "#    How many pennies Matthew Boulton strucked?\n",
    "\n",
    "model = bidirectional_attention_flow_seo_2017()\n",
    "\n",
    "while True:\n",
    "    question = input(\"Input your question\\t\")\n",
    "    \n",
    "    # 1. make a prediction\n",
    "    ans = model.predict(question, passage)\n",
    "\n",
    "    # ensemble the answer\n",
    "    p1, p2 = get_span_probs(ans)\n",
    "    print(f\"\\n{question} --> {build_answer(ans)} | p(start)={p1:.3f}, p(end)={p2:.3f}\\n\")\n",
    "\n",
    "    # plot the attention\n",
    "#     plot_attention(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
